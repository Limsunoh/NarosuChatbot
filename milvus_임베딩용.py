from openai import OpenAI
from pymilvus import (
    connections, utility,
    FieldSchema, CollectionSchema,
    DataType, Collection
)
from dotenv import load_dotenv
import pandas as pd
import re
import tiktoken        
import numpy as np
import time
import os

# â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
API_KEY = os.getenv('OPENAI_API_KEY')
EXCEL_PATH  = "ownerclan_ì£¼ê°„ì¸ê¸°ìƒí’ˆ_0613_2.xlsx"
COLLECTION  = "ownerclan_weekly_0428"
MODEL       = "text-embedding-3-small"
MAX_TOKENS  = 300_000
CHUNK_SIZE  = 5000

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# 1) OpenAI í´ë¼ì´ì–¸íŠ¸ & Milvus ì—°ê²°
client = OpenAI(api_key=API_KEY)
connections.connect(alias="default", host="114.110.135.96", port="19530")

# 2) ì—‘ì…€ ë¡œë“œ
df = pd.read_excel(EXCEL_PATH)


# 3) í•œê¸€â†’ì˜ë¬¸ í•„ë“œëª… ë§¤í•‘
column_map = {
    "ìƒí’ˆì½”ë“œ":        "product_code",    # ë©”íƒ€ë°ì´í„°ë§Œ
    "ì¹´í…Œê³ ë¦¬ì½”ë“œ":    "category_code",   # ë©”íƒ€ë°ì´í„°ë§Œ
    "ì¹´í…Œê³ ë¦¬ëª…":      "category_name",
    "ë§ˆì¼“ìƒí’ˆëª…":      "market_product_name",
    "ë§ˆì¼“ì‹¤ì œíŒë§¤ê°€":  "market_price",
    "ë°°ì†¡ë¹„":          "shipping_fee",
    "ë°°ì†¡ìœ í˜•":        "shipping_type",
    "ìµœëŒ€êµ¬ë§¤ìˆ˜ëŸ‰":    "max_quantity",
    "ì¡°í•©í˜•ì˜µì…˜":      "composite_options",
    "ì´ë¯¸ì§€ì¤‘":        "image_url",        # ë©”íƒ€ë°ì´í„°ë§Œ
    "ì œì‘/ìˆ˜ì…ì‚¬":     "manufacturer",
    "ëª¨ë¸ëª…":          "model_name",
    "ì›ì‚°ì§€":          "origin",
    "í‚¤ì›Œë“œ":          "keywords",
    "ë³¸ë¬¸ìƒì„¸ì„¤ëª…":    "description",       # ë©”íƒ€ë°ì´í„°ë§Œ
    "ë°˜í’ˆë°°ì†¡ë¹„":      "return_shipping_fee",
    "ë…ë¦½í˜•":          "independent_option",  # ì‹ ê·œ
    "ì¡°í•©í˜•":          "composite_flag"       # ì‹ ê·œ
}
numeric_fields = {
    "market_price",
    "shipping_fee",
    "max_quantity",
    "return_shipping_fee",
}

# 4) ê° ì—´ë³„ ìµœëŒ€ ë¬¸ìì—´ ê¸¸ì´ ê³„ì‚° & ì¶œë ¥
print("ì»¬ëŸ¼ëª…(ì˜ë¬¸)         | ì»¬ëŸ¼ëª…(í•œê¸€)     | ìµœëŒ€ ê¸¸ì´")
for kor, eng in column_map.items():
    # strip() ì¶”ê°€í•˜ë©´ ì–‘ìª½ ê³µë°±Â·ê°œí–‰ ì œê±°
    max_len = df[kor].astype(str).str.strip().str.len().max()
    print(f"{eng:20s} | {kor:12s} | {max_len}")

# 5) Milvus ì»¬ë ‰ì…˜ ì¤€ë¹„ (ì¡´ì¬í•˜ë©´ ì‚­ì œ â†’ ì¬ìƒì„±)
if utility.has_collection(COLLECTION):
    utility.drop_collection(COLLECTION)

fields = [  
    FieldSchema("id",                  DataType.INT64,        is_primary=True, auto_id=True),
    FieldSchema("emb",                 DataType.FLOAT_VECTOR, dim=1536),
    FieldSchema("text",                DataType.VARCHAR,      max_length=65535),
    FieldSchema("product_code",        DataType.VARCHAR,      max_length=50),
    FieldSchema("category_code",       DataType.VARCHAR,      max_length=20),
    FieldSchema("category_name",       DataType.VARCHAR,      max_length=256),
    FieldSchema("market_product_name", DataType.VARCHAR,      max_length=512),
    FieldSchema("market_price",        DataType.INT64),
    FieldSchema("shipping_fee",        DataType.INT64),
    FieldSchema("shipping_type",       DataType.VARCHAR,      max_length=16),
    FieldSchema("max_quantity",        DataType.INT64),
    FieldSchema("composite_options",   DataType.VARCHAR,      max_length=16384),
    FieldSchema("image_url",           DataType.VARCHAR,      max_length=2048),
    FieldSchema("manufacturer",        DataType.VARCHAR,      max_length=128),
    FieldSchema("model_name",          DataType.VARCHAR,      max_length=256),
    FieldSchema("origin",              DataType.VARCHAR,      max_length=100),
    FieldSchema("keywords",            DataType.VARCHAR,      max_length=1024),
    FieldSchema("description",         DataType.VARCHAR,      max_length=65535),
    FieldSchema("return_shipping_fee", DataType.INT64),
    FieldSchema("independent_option",   DataType.VARCHAR,      max_length=4096),   # í…ìŠ¤íŠ¸ë¡œ
    FieldSchema("composite_flag",       DataType.VARCHAR,      max_length=16384),   # í…ìŠ¤íŠ¸ë¡œ
]
schema = CollectionSchema(fields, description="Weekly Top 50k Products")
collection = Collection(name=COLLECTION, schema=schema)

# # ì œì™¸í•  í•„ë“œ ëª©ë¡ì— ìƒí’ˆì½”ë“œ, ì¹´í…Œê³ ë¦¬ì½”ë“œ, ì´ë¯¸ì§€ì¤‘ ì¶”ê°€
# exclude_fields = {
#     "ìƒí’ˆì½”ë“œ",            # product_code â€“ ì‚¬ìš©ì ê²€ìƒ‰ì— ì˜ë¯¸ ì—†ìŒ
#     "ì¹´í…Œê³ ë¦¬ì½”ë“œ",        # category_code â€“ ì‹œìŠ¤í…œ ì½”ë“œ
#     "ì´ë¯¸ì§€ì¤‘",            # image_url â€“ ë²¡í„°í™” ë¶ˆê°€ëŠ¥
#     "ëª¨ë¸ëª…",              # model_name â€“ ëŒ€ë¶€ë¶„ NaN ë˜ëŠ” ì œí’ˆë²ˆí˜¸
#     "ìµœëŒ€êµ¬ë§¤ìˆ˜ëŸ‰",        # max_quantity â€“ ê²€ìƒ‰ì—ëŠ” ì˜í–¥ ì—†ìŒ
#     "ë³¸ë¬¸ìƒì„¸ì„¤ëª…"         # description â€“ HTML+ë…¸ì´ì¦ˆ ë©ì–´ë¦¬
# }

# def make_text(row):
#     parts = []
#     for kor, eng in column_map.items():
#         if kor in exclude_fields:
#             continue
#         parts.append(f"{eng}:{row[kor]}")
#     return " || ".join(parts)

# texts = df.apply(make_text, axis=1).tolist()

# 8) ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ìƒì„± (ì¹´í…Œê³ ë¦¬ëª…, ìƒí’ˆëª…, í‚¤ì›Œë“œ, ì¡°í•©í˜•ì˜µì…˜ë§Œ)
def make_text(row):
    return " || ".join([
        f"cat:{row['ì¹´í…Œê³ ë¦¬ëª…']}",
        f"name:{row['ë§ˆì¼“ìƒí’ˆëª…']}",
        f"kw:{row['í‚¤ì›Œë“œ']}",
        f"opts:{row['ì¡°í•©í˜•ì˜µì…˜']}"
    ])

texts = df.apply(make_text, axis=1).tolist()

# 5-1) ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ í™•ì¸ìš© í…Œì´ë¸” ìƒì„±
df_embed_text = df.copy()
df_embed_text["embedding_text"] = texts

# ì„ë² ë”© í…ìŠ¤íŠ¸ ì—´ë§Œ ë³´ê¸° (ì›í•˜ëŠ” ë§Œí¼ í–‰ ì œí•œë„ ê°€ëŠ¥)
print("\nâœ… [ì„ë² ë”© í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°]")
print(df_embed_text[["embedding_text"]].head(10).to_string(index=False))

# 6) í† í° ê¸°ì¤€ ë°°ì¹˜ ë¶„í• 
def split_batches(texts, max_tokens=MAX_TOKENS):
    enc = tiktoken.get_encoding("cl100k_base")
    batches, batch, tokens = [], [], 0
    for t in texts:
        tk = len(enc.encode(t))
        if tokens + tk > max_tokens:
            batches.append(batch)
            batch, tokens = [], 0
        batch.append(t)
        tokens += tk
    if batch:
        batches.append(batch)
    return batches


batches = split_batches(texts)
embeddings = []
for idx, batch in enumerate(batches, 1):
    start = time.time()
    resp = client.embeddings.create(input=batch, model=MODEL)
    embeddings.extend([d.embedding for d in resp.data])
    print(f"ë°°ì¹˜ {idx}/{len(batches)} ì™„ë£Œ: {time.time()-start:.1f}s")
embeddings = np.array(embeddings)


# 8) Milvusì— ì‚½ì… (ìµœì´ˆ 1íšŒë§Œ)
if collection.num_entities == 0:
    n = len(texts)
    total_chunks = (n + CHUNK_SIZE - 1) // CHUNK_SIZE
    for idx, start in enumerate(range(0, n, CHUNK_SIZE), 1):
        end = min(start + CHUNK_SIZE, n)
        chunk_emb = embeddings[start:end].tolist()
        chunk_txt = texts[start:end]
        chunk_meta = [
            (df[kor].astype(int).tolist() if eng in numeric_fields
             else df[kor].astype(str).tolist())[start:end]
            for kor, eng in column_map.items()
        ]

        collection.insert([chunk_emb, chunk_txt] + chunk_meta)
        collection.flush()
        print(f"â–¶ï¸ Milvus ì‚½ì… ì™„ë£Œ: ì²­í¬ {idx}/{total_chunks} (rows {start}â€“{end-1})")
else:
    print("â–¶ï¸ Milvusì— ì´ë¯¸ ë°ì´í„°ê°€ ìˆì–´ ì‚½ì… ìŠ¤í‚µ")

# 9) ì¸ë±ìŠ¤ ìƒì„± & ë¡œë“œ (í•œ ë²ˆë§Œ)
print("â–¶ï¸ ì¸ë±ìŠ¤ ìƒì„± ì¤‘â€¦")
collection.create_index(
    field_name="emb",
    index_params={"index_type":"IVF_FLAT","metric_type":"L2","params":{"nlist":128}}
)
print("â–¶ï¸ ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ, ì»¬ë ‰ì…˜ ë¡œë“œ ì¤‘â€¦")
collection.load()
print("â–¶ï¸ ì»¬ë ‰ì…˜ ë¡œë“œ ì™„ë£Œ")

# 10) ê²€ìƒ‰ í•¨ìˆ˜
def semantic_search_with_price(query, top_k=5):
    m = re.search(r'(\d+)\s*ì›', query)
    price = int(m.group(1)) if m else None

    q_emb = client.embeddings.create(input=[query], model=MODEL).data[0].embedding
    expr = f"market_price <= {price}" if price else None

    results = collection.search(
        data=[q_emb],
        anns_field="emb",
        param={"metric_type":"L2","params":{"nprobe":30}},   #nprobe=20~30 â†’ recall 90% ì´ìƒ ëª©í‘œ
        limit=top_k,
        expr=expr,
        output_fields=list(column_map.values()) + ["text"]
    )
    print(f"\nğŸ” Query: {query}" + (f" (â‰¤{price}ì›)" if price else ""))
    for hit in results[0]:
        print(f" â€¢ {hit.entity.get('market_product_name')} â€” "
              f"{hit.entity.get('market_price')}ì› (dist={hit.distance:.3f})")

# 11) ì˜ˆì‹œ ì‹¤í–‰
if __name__ == "__main__":
    semantic_search_with_price("ìº í•‘ìš©í’ˆ ì¶”ì²œí•´ì¤˜", 5)
    semantic_search_with_price("ì—¬ë¦„ í‹°ì…”ì¸  ì¤‘ 3000ì› ì´í•˜", 5)
    semantic_search_with_price("í° ê°€ë°© ì¶”ì²œí•´ì¤˜ì¤˜", 5)
    semantic_search_with_price("ì—¬ë¦„ìš© ì–‡ì€ ê°•ì•„ì§€ ì˜· ì¶”ì²œë°›ê³  ì‹¶ì–´ìš”", 5)
    semantic_search_with_price("ì„¬ìœ ìœ ì—°ì œ", 5)
    semantic_search_with_price("ë‚¨ì„±í‹°ì…”ì¸ ", 5)
    semantic_search_with_price("ê²¨ìš¸ìš©í’ˆ ì¶”ì²œí•´ì¤˜", 5)