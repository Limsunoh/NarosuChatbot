from dotenv import load_dotenv
import os
import pandas as pd
import json
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
import faiss
import numpy as np
from datetime import datetime
from fastapi import FastAPI, HTTPException, Request
from fastapi.templating import Jinja2Templates
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
import uvicorn
from fastapi.middleware.cors import CORSMiddleware
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from langchain.memory import ConversationBufferMemory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import RedisChatMessageHistory
from langchain_core.runnables import ConfigurableFieldSpec
import redis
import requests
from typing import Union
import logging
import time
import asyncio
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm  # ì§„í–‰ ë°” ì¶”ê°€
from sentence_transformers import SentenceTransformer


executor = ThreadPoolExecutor()

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ+
load_dotenv()
API_KEY = os.getenv('OPENAI_API_KEY')
REDIS_URL = "redis://localhost:6379/0"
VERIFY_TOKEN = os.getenv('VERIFY_TOKEN')
PAGE_ACCESS_TOKEN = os.getenv('PAGE_ACCESS_TOKEN')
MANYCHAT_API_KEY = os.getenv('MANYCHAT_API_KEY')

print(f"ğŸ” ë¡œë“œëœ VERIFY_TOKEN: {VERIFY_TOKEN}")
print(f"ğŸ” ë¡œë“œëœ PAGE_ACCESS_TOKEN: {PAGE_ACCESS_TOKEN}")


# âœ… FAISS ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •
FAISS_INDEX_PATH = "faiss_index_03M.faiss"  # ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ ê²½ë¡œ

BERT_MODEL_NAME = "sentence-transformers/paraphrase-MiniLM-L6-v2"

# âœ… ì—¬ëŸ¬ ê°œì˜ ì—‘ì…€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
excel_files = [
    "db/file1.xlsx",
    "db/file2.xlsx",
    "db/file3.xlsx",
    "db/file4.xlsx"
]

# âœ… ì—‘ì…€ ë°ì´í„° ë¡œë“œ ë° ë³€í™˜ í•¨ìˆ˜
# âœ… ì—‘ì…€ ë°ì´í„° ë¡œë“œ ë° ë³€í™˜ í•¨ìˆ˜
def load_excel_to_texts(file_path):
    """ì—‘ì…€ íŒŒì¼ì„ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    try:
        data = pd.read_excel(file_path)
        data.columns = data.columns.str.strip()
        texts = [" | ".join([f"{col}: {row[col]}" for col in data.columns]) for _, row in data.iterrows()]
        return texts, data
    except Exception as e:
        raise Exception(f"âŒ ì—‘ì…€ ë¡œë“œ ì˜¤ë¥˜: {e}")

# âœ… FAISS ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ë©´ ë¡œë“œ, ì—†ìœ¼ë©´ ìƒì„±
if os.path.exists(FAISS_INDEX_PATH):
    print(f"âœ… ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ ë°œê²¬: {FAISS_INDEX_PATH}, ì„ë² ë”© ìƒëµ")
    index = faiss.read_index(FAISS_INDEX_PATH)
else:
    print("ğŸš€ FAISS ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ, ìƒˆë¡œ ìƒì„± ì¤‘...")

    # âœ… ì—¬ëŸ¬ ê°œì˜ ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ì„œ ë²¡í„° ë³€í™˜
    all_texts = []
    for file in tqdm(excel_files, desc="ğŸ“‚ ì—‘ì…€ íŒŒì¼ ë¡œë“œ ì¤‘"):
        texts, _ = load_excel_to_texts(file)
        all_texts.extend(texts)

    print(f"ğŸ” ì´ {len(all_texts)}ê°œì˜ ë¬¸ì¥ì„ ì„ë² ë”©í•©ë‹ˆë‹¤.")

    # âœ… BERT ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    embedding_model = SentenceTransformer(BERT_MODEL_NAME)

    # âœ… ë°°ì¹˜ ë‹¨ìœ„ë¡œ BERT ì„ë² ë”© ìƒì„±
    all_embeddings = []
    BATCH_SIZE = 200
    for i in tqdm(range(0, len(all_texts), BATCH_SIZE), desc="ğŸš€ BERT ì„ë² ë”© ì§„í–‰ ì¤‘"):
        batch_texts = all_texts[i:i+BATCH_SIZE]
        batch_embeddings = embedding_model.encode(batch_texts, convert_to_numpy=True, normalize_embeddings=True)
        all_embeddings.extend(batch_embeddings)

    # âœ… FAISS ë²¡í„° ë³€í™˜
    embeddings = np.array(all_embeddings, dtype=np.float32)

    # âœ… FAISS ì¸ë±ìŠ¤ ìƒì„± (IndexIVFFlat ì‚¬ìš©)
    d = embeddings.shape[1]
    nlist = 200
    quantizer = faiss.IndexFlatL2(d)
    index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)

    print("ğŸ”§ FAISS ì¸ë±ìŠ¤ í•™ìŠµ ì¤‘...")
    index.train(embeddings)
    
    print("ğŸ“Œ FAISS ì¸ë±ìŠ¤ ë°ì´í„° ì¶”ê°€ ì¤‘...")
    index.add(embeddings)

    # âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥ (ê¸°ì¡´ ê²½ë¡œ ìœ ì§€)
    faiss.write_index(index, FAISS_INDEX_PATH)
    print(f"âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: {FAISS_INDEX_PATH}")